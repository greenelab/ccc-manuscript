### A robust and efficient not-only-linear dependence coefficient

![
**Different types of relationships in data.**
Each panel contains a set of simulated data points described by two generic variables: $x$ and $y$.
The first row shows Anscombe's quartet with four different datasets (from Anscombe I to IV) and 11 data points each.
The second row contains a set of general patterns with 100 data points each.
Each panel shows the correlation value using Pearson ($p$), Spearman ($s$) and CCC ($c$).
Vertical and horizontal red lines show how CCC clustered data points using $x$ and $y$.
](images/intro/relationships.svg "Different types of relationships in data"){#fig:datasets_rel width="100%"}

The CCC provides a similarity measure between any pair of variables, either with numerical or categorical values.
It assumes that if there is a relationship between two variables/features describing $n$ data points/objects, the clusterings of those objects using each variable should match.
For numerical values, CCC uses quantiles to separate data points into different clusters (e.g., the median separates numerical data into two clusters).
The CCC is then defined as the maximum adjusted Rand index (ARI) between the clusterings, ranging from 0 to 1.
Further details of the CCC algorithm can be found in the Methods section.


We examined the behavior of the Pearson ($p$), Spearman ($s$), and CCC ($c$) correlation coefficients on different simulated data patterns.
Figure @fig:datasets_rel shows the classic Anscombe's quartet [@doi:10.1080/00031305.1973.10478966], which contains four synthetic datasets with various patterns, but the same data statistics (mean, standard deviation, and Pearson's correlation).
The "Datasaurus" [@url:http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html; @doi:10.1145/3025453.3025912; @doi:10.1111/dsji.12233] recently revisited this kind of simulated data to remind us of the importance of going beyond simple statistics.
Summary statistics alone can mask undesirable patterns (such as outliers) or desirable ones (such as biologically meaningful nonlinear relationships).


In contrast, CCC is able to capture nonlinear relationships and outliers, providing a more accurate measure of correlation.

The Anscombe datasets demonstrate the effectiveness of CCC in detecting correlation.
In Anscombe I and III, CCC yields a value of 1.0, indicating a strong linear relationship.
In Anscombe II, CCC yields a lower yet non-zero value of 0.34, reflecting a more complex relationship than a linear pattern.
In Anscombe IV, CCC yields the minimum value of 0.00, correctly indicating no association between the variables, due to the presence of an outlier.
Pearson's correlation coefficient yields the same value across all the Anscombe examples, whereas Spearman's correlation coefficient is 0.50 or greater.
The results show that CCC is more robust than Pearson and Spearman in capturing nonlinear relationships and outliers, and is thus a more accurate measure of correlation.


We simulated additional types of relationships (shown in Figure @fig:datasets_rel, second row) including some previously described from gene expression data [@doi:10.1126/science.1205438; @doi:10.3389/fgene.2019.01410; @doi:10.1091/mbc.9.12.3273].
For the random/independent pair of variables, all correlation coefficients correctly agreed with a value close to zero.
The non-coexistence pattern, captured by all coefficients, represented a case where one gene ($x$) might be expressed while the other one ($y$) was inhibited, highlighting a potentially strong biological relationship (such as a microRNA negatively regulating another gene).
For the other two examples (quadratic and two-lines), Pearson and Spearman did not capture the nonlinear pattern between variables $x$ and $y$.
CCC, however, used different degrees of complexity to capture the relationships.
For the quadratic pattern, for example, CCC separated $x$ into four clusters to reach the maximum ARI.
The two-lines example showed two embedded linear relationships with different slopes, which neither Pearson nor Spearman detected ($p=-0.12$ and $s=0.05$, respectively).
Here, CCC increased the complexity of the model by using eight clusters for $x$ and six for $y$, resulting in $c=0.31$.
