### A robust and efficient not-only-linear dependence coefficient

The Clustermatch Correlation Coefficient (CCC) provides a similarity measure between any pair of variables, either with numerical or categorical values.
The method assumes that if there is a relationship between two variables/features describing $n$ data points/objects, then the partitioning of those $n$ objects derived by clustering each variable individually should match.
In CCC, the data is internally categorized into clusters, therefore numerical and categorical variables can be naturally integrated since clusters do not need an order.
In the case of numerical values, CCC uses quantiles to efficiently separate data points into different clusters (e.g., the median separates numerical data into two clusters), whereas for categorical variables data points are grouped together if they share the same category.
Once all partitions according to each variable are generated, CCC is defined as the maximum adjusted Rand index (ARI) [@doi:10.1007/BF01908075] between them, which ranges between 0 and 1.
Details of the CCC algorithm can be found in Methods.


![
**Different types of relationships in data.**
Each panel contains a set of simulated data points described by two variables: $x$ and $y$.
The first row shows Anscombe's quartet with four different datasets (from Anscombe I to IV) and 11 data points each.
The second row contains a set of general patterns with 100 data points each.
Each panel shows the correlation value using Pearson ($p$), Spearman ($s$) and the CCC ($c$).
Vertical and horizontal lines show how CCC partitioned data points using $x$ and $y$, respectively.
](images/intro/relationships.svg "Different types of relationships in data"){#fig:datasets_rel width="100%"}


First, we examined how the Pearson ($p$), Spearman ($s$) and Clustermatch ($c$) correlation coefficients behaved on different simulated data patterns.
In the first row of Figure @fig:datasets_rel, we examine the classic Anscombe's quartet [@doi:10.1080/00031305.1973.10478966], where red lines indicate how CCC clusters data points using each variable/feature individually (either $x$ or $y$).
This dataset comprises four synthetic datasets with entirely different patterns but the same data statistics (mean, standard deviation and Pearson's correlation).
This kind of simulated data, recently revisited with the "Datasaurus" [@url:http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html; @doi:10.1145/3025453.3025912; @doi:10.1111/dsji.12233], is used as a reminder of the importance of going beyond simple statistics, where either undesirable patterns (such as outliers) or desirable ones (such as biologically meaningful non-linear relationships) can be masked by summary statistics alone.
<!--The parts below this are more describing what is in the figure - could you instead interpret the figure? what do we learn about the coefficients from this? i think you need more interpretation and less description-->
For example, Anscombe I contains a noisy but clear linear pattern, similar to Anscombe III where the linearity is perfect besides one outlier.
In these two examples, CCC separates data points using two clusters (one red line for each variable $x$ and $y$), yielding 1.0, indicating a strong relationship.
Anscombe II seems to follow a quadratic relationship interpreted as a linear pattern by Pearson and Spearman, whereas CCC yields a lower yet non-zero value of 0.34, reflecting a relationships that is more complex than a linear relationship.
Anscombe IV shows a vertical line where $x$ values are almost constant except for one outlier.
This outlier does not influence CCC as it does for Pearson or Spearman.
Thus $c=0.00$ (the minimum value) correctly indicates no association for this variable pair because, besides the outlier, for a single value of $x$ there are ten different values for $y$.
This variable pair does not fit the CCC assumption: the two clusters formed with $x$ (approximately separated by $x=13$) do not match the three clusters formed with $y$.
The Pearson's correlation coefficient is the same across all these Anscombe's examples ($p=0.82$), whereas Spearman is always above or equal to 0.50.
These simulated datasets show that both Pearson and Spearman are very powerful to detect linear patterns, although any deviation in this assumption (like non-linear patterns or outliers) affects their robustness.
One reason for this behavior is that these coefficients are based on data statistics alone, such as the mean, standard deviation or simple rankings, which seem to fall short in dealing with noisy data or more complex patterns.


The second row of Figure @fig:datasets_rel shows other simulated relationships with general non-linear patterns, some of which were previously observed in gene expression data [@doi:10.1126/science.1205438; @doi:10.3389/fgene.2019.01410; @doi:10.1091/mbc.9.12.3273].
For the random/independent pair of variables, all coefficients correctly agree with a value close to zero.
The non-coexistence pattern, correctly captured by all coefficients, represents a case where one gene ($x$) might be expressed while the other one ($y$) is inhibited, highlighting a potentially strong biological relationship (such as a microRNA negatively regulating another gene).
For the other two examples (quadratic and two-lines), Pearson and Spearman do not capture the non-linear pattern between variables $x$ and $y$.
These patterns also show how CCC uses different degrees of complexity to capture the relationships.
For the quadratic pattern, for example, CCC separates $x$ into more clusters (four in this case) to reach the maximum ARI.
The two-lines example shows two embedded linear relationships with different slopes, which neither Pearson nor Spearman detect ($p=-0.12$ and $s=0.05$, respectively).
Here, CCC increases the complexity of the model by using eight clusters for $x$ and six for $y$, resulting in $c=0.31$.


Datasets such as Anscombe or "Datasaurus" highlight the value of visualization instead of relying on simple data summaries.
While visual analysis is helpful, for many datasets examining each possible relationship is infeasible and this is where more sophisticated and robust correlation coefficients are necessary.
Advanced yet interpretable coefficients can focus human interpretation on patterns that are more likely to reflect real biology.
Those that capture non-linear patterns can reveal relationships missed by the linear-only coefficients that are often deployed.
