### A robust and efficient not-only-linear dependence coefficient

![
**Different types of relationships in data.**
Each panel contains a set of simulated data points described by two generic variables: $x$ and $y$.
The first row shows Anscombe's quartet with four different datasets (from Anscombe I to IV) and 11 data points each.
The second row contains a set of general patterns with 100 data points each.
Each panel shows the correlation value using Pearson ($p$), Spearman ($s$) and CCC ($c$).
Vertical and horizontal red lines show how CCC clustered data points using $x$ and $y$.
](images/intro/relationships.svg "Different types of relationships in data"){#fig:datasets_rel width="100%"}

The CCC provides a similarity measure between any pair of variables, either with numerical or categorical values.
It assumes that if two variables/features have a relationship, the clusterings of the data points using each variable should match.
To separate numerical data points into different clusters, CCC uses quantiles (e.g., the median divides the data into two clusters).
The CCC is then defined as the maximum adjusted Rand index (ARI) [@doi:10.1007/BF01908075] between the clusterings, ranging from 0 to 1.
Further details of the CCC algorithm can be found in the Methods section.


We evaluated the performance of the Pearson, Spearman and CCC correlation coefficients on different simulated data patterns.
Figure @fig:datasets_rel shows the results of our analysis of Anscombe's quartet [@doi:10.1080/00031305.1973.10478966], which comprises four synthetic datasets with different patterns but the same data statistics (mean, standard deviation and Pearson's correlation).
We used this kind of simulated data, recently revisited with the "Datasaurus" [@url:http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html; @doi:10.1145/3025453.3025912; @doi:10.1111/dsji.12233], to emphasize the importance of going beyond simple statistics.
This is because summary statistics can mask undesirable patterns (such as outliers) and desirable ones (such as biologically meaningful nonlinear relationships).


In contrast, CCC yields more accurate results for nonlinear relationships and outliers.

The Anscombe I dataset contains a noisy but clear linear pattern, and Anscombe III has a perfect linear pattern with one outlier.
For these two datasets, CCC yields a value of 1.0, indicating a strong relationship between the variables $x$ and $y$.
In contrast, Anscombe II appears to have a partially quadratic relationship, which is interpreted as linear by Pearson and Spearman.
CCC yields a lower yet non-zero value of 0.34, reflecting a more complex relationship than a linear pattern.
Anscombe IV has a vertical line of data points with $x$ values that are almost constant, except for one outlier.
CCC correctly indicates no association for this variable pair with a value of 0.00, since, besides the outlier, there are ten different values for $y$ for a single value of $x$.
The Pearson and Spearman correlation coefficients are the same across all four Anscombe's examples ($p=0.82$ and $s=0.50$ or greater).
These simulated datasets show that Pearson and Spearman are powerful in detecting linear patterns, but any deviation from this assumption, such as nonlinear relationships or outliers, affects their robustness.
In contrast, CCC yields more accurate results for nonlinear relationships and outliers.


We simulated additional types of relationships between two variables (Figure @fig:datasets_rel, second row), including some previously described from gene expression data [@doi:10.1126/science.1205438; @doi:10.3389/fgene.2019.01410; @doi:10.1091/mbc.9.12.3273].
For the random/independent pair of variables, our correlation coefficient correctly agreed with a value close to zero.
The non-coexistence pattern, captured by all coefficients, represented a case where one gene ($x$) was expressed while the other one ($y$) was inhibited, highlighting a potentially strong biological relationship (such as a microRNA negatively regulating another gene).
Pearson and Spearman, however, did not capture the nonlinear patterns between variables $x$ and $y$ for the quadratic and two-lines examples.
CCC, however, increased its complexity by using different degrees of complexity to capture the relationships.
For the quadratic pattern, for example, CCC separated $x$ into four clusters to reach the maximum ARI.
The two-lines example showed two embedded linear relationships with different slopes, which neither Pearson nor Spearman detected ($p=-0.12$ and $s=0.05$, respectively).
Here, CCC used eight clusters for $x$ and six for $y$, resulting in $c=0.31$.
