## Methods

The code needed to reproduce all of our analyses and generate the figures is available in [@url:https://github.com/greenelab/clustermatch-gene-expr].
We provide scripts to automatically download the required data and run all the steps.
A Docker image is provided to use exactly the same runtime environment.



### The CCC algorithm {#sec:ccc_algo}

The Clustermatch Correlation Coefficient (CCC) computes a similarity value $c \in \left[0,1\right]$ between any pair of numerical or categorical features/variables $\mathbf{x}$ and $\mathbf{y}$ measured on $n$ objects.
CCC assumes that if two features $\mathbf{x}$ and $\mathbf{y}$ are similar, then the partitioning of the $n$ objects using each feature separately should match.
For example, given $\mathbf{x}=(1.1, 2.7, 3.2, 4.0)$ and $\mathbf{y}=10x=(11, 27, 32, 40)$ for $n=4$, partitioning each variable into two clusters ($k=2$) using their medians (2.95 for $\mathbf{x}$ and 29.5 for $\mathbf{y}$) would result in partition $\pi^{\mathbf{x}}=(1, 1, 2, 2)$ for $\mathbf{x}$, and partition $\pi^{\mathbf{y}}=(1, 1, 2, 2)$ for $\mathbf{y}$.
If we compute the agreement between $\pi^{\mathbf{x}}$ and $\pi^{\mathbf{y}}$ using any measure of similarity between partitions, like the adjusted Rand index (ARI) [@doi:10.1007/BF01908075], it will return the maximum value (1.0 in the case of ARI).
For CCC, a given value of $k$ might not be the right one to find a relationship between two features.
For instance, in the quadratic example in Figure @fig:datasets_rel, CCC returns a value of 0.36 (grouping objects in four clusters using one feature, and two using the other).
If we used only two clusters in this example, CCC would return a similarity value of 0.02.
The CCC algorithm (shown below) searches for this optimal number of clusters given a maximum $k$, which is its single parameter $k_{\mathrm{max}}$.

![
](images/intro/ccc_algorithm/ccc_algorithm.svg "CCC algorithm"){width="80%"}

The main function of the algorithm, `ccc`, generates a list of partitionings $\pi^{\mathbf{x}}$ and $\pi^{\mathbf{y}}$ (lines 14 and 15), for each feature $\mathbf{x}$ and $\mathbf{y}$.
Then, it computes the ARI between each partition in $\pi^{\mathbf{x}}$ and $\pi^{\mathbf{y}}$ (line 16), and then it keeps the pair that generates the maximum ARI.
Finally, since ARI does not have a lower bound (it could return negative values, which in our case are not meaningful), CCC always returns a value between 0 and 1 (line 17).


Since CCC only needs a pair of partitions to compute a similarity, any type of feature that can be used to perform clustering/grouping of the $n$ objects is supported.
If the feature is numerical (lines 2 to 5 in the `get_partitions` function), then quantiles are used for clustering (for example, the median generates $k=2$ clusters of objects), from $k=2$ to $k=k_{\mathrm{max}}$.
If the feature is categorical (lines 7 to 9), then the categories are used to group objects together.
Consequently, since features are internally categorized into clusters, numerical and categorical variables can be naturally integrated since clusters do not need an order.
Actually, although not developed in this study, CCC provides a framework where not only 1-dimensional variables can be compared (such as genes across $n$ samples), but in theory also random vectors (multivariate random variables) such as an image.


For all our analyses we used $k_{\mathrm{max}}=10$.
This means that for each gene pair, 20 partitions are generated (10 for each gene) and 100 ARI comparisons are performed.
Smaller values of $k_{\mathrm{max}}$ can reduce compute time, although at the expense of missing more complex, general relationships.
Our examples in Figure @fig:datasets_rel suggest that using $k_{\mathrm{max}}=2$ would force CCC to find linear-only patterns, which could be a valid use case scenario where only this kind of relationships are desired.
In addition, $k_{\mathrm{max}}=2$ implies that only two partitions are generated and only one ARI comparisons is performed.


For a single pair of features (genes in our study), generating partitions or computing their similarity can be parallelized with CCC.
We used three CPU cores in our analyses to speed up the computation of CCC.
A future improved implementation of CCC could potentially use graphical processing units (GPU) to futher parallelize its computation.


A Python implementation of CCC (optimized with `numba` [@doi:10.1145/2833157.2833162]) can be found in our Github repository [@url:https://github.com/greenelab/clustermatch-gene-expr], as well as a package published in the Python Package Index (PyPI) that can be easily installed.



### Maximal Information Coefficient (MIC) {#sec:methods:mic}

We used the Python package `minepy` [@doi:10.1093/bioinformatics/bts707; @url:https://github.com/minepy/minepy] (version 1.2.5) to estimate the MIC coefficient.
In GTEx v8 (whole blood), we ran MIC (the original implementation using the heuristic estimator ApproxMaxMI [@doi:10.1126/science.1205438]) with the default parameters `alpha=0.6`, `c=15` and `estimator='mic_approx'`.
For our computational complexity analyses (see [Supplementary Material](#sec:time_test)), we also ran a new optimized implementation called MIC<sub>e</sub> [@Reshef2016] provided by `minepy` (using parameter `estimator='mic_e'`).



### Gene expression data, preprocessing and sampling {#sec:data_gtex}

We downloaded GTEx v8 data for all tissues, normalized using TPM (transcripts per million), and focused our primary analysis on whole blood, which has a good sample size (755).
We selected the top 5,000 genes from whole blood with the largest variance after standardizing with $log(x + 1)$ to avoid a bias towards highly-expressed genes.
We then computed Pearson, Spearman and CCC on these 5,000 genes across all 755 samples on the TPM-normalized data, generating a pairwise similarity matrix of size 5,000 x 5,000.
To reduce the time to compute MIC and compare it with the other coefficients, we randomly sampled 100,000 gene pairs from all possible combinations in this set of 5,000 genes ($n * (n-1) / 2=12497500$).



### Tissue-specific network analyses using GIANT {#sec:giant}

We accessed tissue-specific gene networks of GIANT using both the web interface and web services provided by HumanBase [@url:https://hb.flatironinstitute.org/].
The GIANT version used in this study included 987 genome-scale datasets with a total of approximately 38,000 conditions from an estimated number of 14,000 publications.
Details are how these networks were built are described in [@doi:10.1038/ng.3259].
Briefly, tissue-specific gene networks were built using gene expression data (without GTEx samples [@url:https://hb.flatironinstitute.org/data]) from the NCBI's Gene Expression Omnibus (GEO) [@doi:10.1093/nar/gks1193], protein-protein interaction (BioGRID [@pmc:PMC3531226], IntAct [@doi:10.1093/nar/gkr1088], MINT [@doi:10.1093/nar/gkr930] and MIPS [@pmc:PMC148093]), transcription factor regulation using binding motifs from JASPAR [@doi:10.1093/nar/gkp950], and chemical and genetic perturbations from MSigDB [@doi:10.1073/pnas.0506580102].
Gene expression data was log transformed, and the Pearson correlation was computed for each gene pair, normalized using the Fisher's z transform, and z-scores discretized into different bins.
Gold standards for tissue functional relationships were built using expert curation and experimentally derived gene annotations from the Gene Ontology.
Then, one naive Bayesian classifier for each of the 144 tissues was trained using these gold standards.
Finally, these classifiers were used to estimate a probability of tissue-specific interactions for each gene pair.


For each pair of genes prioritized in our study using GTEx, we obtained
1) a predicted gene network for blood (manually selected to match whole blood in GTEx) and
2) a gene network with an automatically predicted tissue using the method described in [@doi:10.1101/gr.155697.113] and provided by HumanBase web interfaces/services.
Briefly, the approach trains a machine learning model using comprehensive transcriptional data with human-curated markers of different cell lineages (e.g., macrophages) as gold standards.
Then, these models are used to predict additional cell lineage-specific genes.
In addition to reporting this predicted tissue or cell lineage, we computed the average probability of interaction between all genes in the network retrieved from GIANT.
Following the default procedure used in GIANT, for each network we included the top 15 genes with the highest probability of interaction with the queried gene pair. 
